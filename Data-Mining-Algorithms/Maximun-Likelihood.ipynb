{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "669dcc3e-1841-424b-801e-27279bdbb6a7",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #00008B; padding: 20px;\">\n",
    "    <h1 style=\"font-size: 100px; color: #ffffff;\">Maximum Likelihood Estimation (MLE)</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce097c90-a588-4f22-9d0c-f0d1608d1edd",
   "metadata": {},
   "source": [
    "<div style=\"border: 2px solid purple; border-radius: 10px; padding: 15px; background-color: #f9f2ff;\">\n",
    "\n",
    "### Maximum Likelihood Estimation (MLE)\n",
    "\n",
    "\n",
    "**Maximum Likelihood Estimation (MLE)** is a method used to estimate the parameters of a statistical model. It does this by finding the parameter values that maximize the likelihood function, which measures how well the model explains the observed data.\n",
    "\n",
    "**Mathematical Formula:**\n",
    "\n",
    "Given a set of $ n $ independent and identically distributed (i.i.d.) data points $ \\{x_1, x_2, ..., x_n\\} $, the likelihood function $ L(\\theta) $ for a parameter $ \\theta $ is defined as:\n",
    "\n",
    "$$ L(\\theta) = \\prod_{i=1}^{n} f(x_i | \\theta) $$\n",
    "\n",
    "where $ f(x_i | \\theta) $ is the probability density function (or probability mass function) of the data point $ x_i $ given the parameter $ \\theta $.\n",
    "\n",
    "The log-likelihood function is often used for convenience:\n",
    "\n",
    "$$ \\log L(\\theta) = \\sum_{i=1}^{n} \\log f(x_i | \\theta) $$\n",
    "\n",
    "MLE finds the parameter $ \\theta $ that maximizes the log-likelihood function:\n",
    "\n",
    "$$ \\hat{\\theta} = \\arg \\max_{\\theta} \\log L(\\theta) $$\n",
    "\n",
    "### Akaike Information Criterion (AIC)\n",
    "\n",
    "**Akaike Information Criterion (AIC)** is a measure used for model selection. It evaluates the trade-off between the goodness of fit of the model and the complexity of the model. A lower AIC value indicates a better model.\n",
    "\n",
    "**Mathematical Formula:**\n",
    "\n",
    "$$ \\text{AIC} = 2k - 2\\log L(\\hat{\\theta}) $$\n",
    "\n",
    "where:\n",
    "- $ k $ is the number of parameters in the model.\n",
    "- $ \\log L(\\hat{\\theta}) $ is the log-likelihood of the model evaluated at the MLE.\n",
    "\n",
    "### Bayesian Information Criterion (BIC)\n",
    "\n",
    "**Bayesian Information Criterion (BIC)** is another criterion for model selection that, like AIC, balances model fit and complexity. BIC tends to penalize model complexity more strongly than AIC.\n",
    "\n",
    "**Mathematical Formula:**\n",
    "\n",
    "$$ \\text{BIC} = k \\log n - 2\\log L(\\hat{\\theta}) $$\n",
    "\n",
    "where:\n",
    "- $ k $ is the number of parameters in the model.\n",
    "- $ n $ is the number of data points.\n",
    "- $ \\log L(\\hat{\\theta}) $ is the log-likelihood of the model evaluated at the MLE.\n",
    "\n",
    "Both AIC and BIC are useful tools in model selection, with BIC typically being more conservative in terms of penalizing complexity.\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a8b40b-3e7a-4ee4-846e-873012e5adf5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
